{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0931e6b2-0478-4a7a-8901-33abf99d33f5",
   "metadata": {},
   "source": [
    "# Recommendation on the MovieLens dataset\n",
    "This notebook demonstrates the use of multiple recommendation algorithms on the MovieLens-1M dataset.\n",
    "\n",
    "Algorithms used include:\n",
    "- Sequenial recommendation algorithms, **SASRec** and **BERT4Rec**\n",
    "- Matrix factorization techniques (in progress, not included yet)\n",
    "\n",
    "Experiment:\n",
    "For each user, we will...\n",
    "- hold out the latest movie by them. \n",
    "- train a model based on all the preceding movies\n",
    "- return the top 100 movies predicted by the model to see if the held-out movie was included\n",
    "\n",
    "***NOTE***  \n",
    "*We only care about movies that were watched and **rated highly (>= 4)**. Anything else is ignored!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9b35cd-87c3-47b3-9738-2dd0852c6c47",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e069783-6744-4b03-b29b-ebb73b49ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sasrec import SASRec, SASRecDataset\n",
    "from bert4rec import BERT4Rec, BERT4RecDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb26f77a-8a8a-4740-8ed4-86398841f2bc",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "***NOTE***  \n",
    "*It is assumed that that MovieLens-1M dataset has already been downloaded and placed next to this notebook in a folder named `ml-1m`.*\n",
    "\n",
    "This is what'll happen below:\n",
    "- After loading the data, sort each user's sequence of movie ratings chronologically.\n",
    "- If a user's sequence is less than 3 movie ratings long, use all movie ratings for training. Otherwise, use all but the last two ratings for training, second-to-last rating for validation and the last rating for testing.\n",
    "- After that, we'll sample \"negative\" examples to use for training alongside the actual movies that were selected/rated by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6df0c",
   "metadata": {},
   "source": [
    "### Preprocess MovieLens 1M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf410d",
   "metadata": {},
   "source": [
    "#### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd5fa51-2ab5-403c-9f2d-3273b761a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings data\n",
    "ratings = pd.read_csv(\n",
    "    \"ml-1m/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"user\", \"item\", \"rating\", \"timestamp\"]\n",
    ")\n",
    "\n",
    "# Keep ratings >= 4\n",
    "ratings = ratings[ratings[\"rating\"] >= 4]\n",
    "\n",
    "# Map to consecutive IDs \n",
    "# (some users/movies disappeared from ratings df after previous step)\n",
    "user2id = {u: i+1 for i, u in enumerate(ratings[\"user\"].unique())}\n",
    "item2id = {m: i+1 for i, m in enumerate(ratings[\"item\"].unique())}\n",
    "ratings[\"user\"] = ratings[\"user\"].map(user2id)\n",
    "ratings[\"item\"] = ratings[\"item\"].map(item2id)\n",
    "\n",
    "n_users = len(user2id)\n",
    "n_items = len(item2id)\n",
    "\n",
    "# Build user sequences\n",
    "user_sequences = defaultdict(list)\n",
    "for row in ratings.itertuples(index=False):\n",
    "    user_sequences[row.user].append((row.item, row.timestamp))\n",
    "\n",
    "# Sort by time\n",
    "for u in user_sequences:\n",
    "    user_sequences[u] = [x[0] for x in sorted(user_sequences[u], key=lambda x: x[1])]\n",
    "\n",
    "# Leave-one-out split\n",
    "train_seqs, valid_seqs, test_seqs = {}, {}, {}\n",
    "for u, items in user_sequences.items():\n",
    "    if len(items) < 3:\n",
    "        train_seqs[u] = items\n",
    "        valid_seqs[u], test_seqs[u] = [], []\n",
    "    else:\n",
    "        train_seqs[u] = items[:-2]\n",
    "        valid_seqs[u] = [items[-2]]\n",
    "        test_seqs[u] = [items[-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7cc7ec",
   "metadata": {},
   "source": [
    "#### Movie Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "157c9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies for item names\n",
    "movies = pd.read_csv(\n",
    "    \"ml-1m/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    names=[\"item\", \"title\", \"genres\"], encoding='latin-1'\n",
    ")\n",
    "movies[\"item\"] = movies[\"item\"].map(item2id)\n",
    "itemid2name = dict(zip(movies[\"item\"], movies[\"title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a2fc9",
   "metadata": {},
   "source": [
    "## Train & Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcc5991",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63596e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU support\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d8a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max sequence length for sequential recommenders\n",
    "MAX_SEQ_LEN = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff5318",
   "metadata": {},
   "source": [
    "### Training (SASRec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4516ea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 4.1632\n",
      "Epoch 2, Loss: 3.3145\n",
      "Epoch 3, Loss: 3.1876\n",
      "Epoch 4, Loss: 2.5853\n",
      "Epoch 5, Loss: 2.3459\n",
      "Epoch 6, Loss: 2.1365\n",
      "Epoch 7, Loss: 1.8776\n",
      "Epoch 8, Loss: 1.7370\n",
      "Epoch 9, Loss: 1.5095\n",
      "Epoch 10, Loss: 1.3991\n",
      "Epoch 11, Loss: 1.2741\n",
      "Epoch 12, Loss: 1.0858\n",
      "Epoch 13, Loss: 0.9553\n",
      "Epoch 14, Loss: 0.8929\n",
      "Epoch 15, Loss: 0.7823\n",
      "Epoch 16, Loss: 0.7402\n",
      "Epoch 17, Loss: 0.7076\n",
      "Epoch 18, Loss: 0.6953\n",
      "Epoch 19, Loss: 0.6708\n",
      "Epoch 20, Loss: 0.6683\n"
     ]
    }
   ],
   "source": [
    "# Prepare training set\n",
    "train_dataset = SASRecDataset(user_sequences, n_items, max_len=MAX_SEQ_LEN, num_negatives=10)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = SASRec(n_items, hidden_dim=64, max_len=MAX_SEQ_LEN).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(20):  # small demo run\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for seq, pos, neg in train_loader:\n",
    "        seq, pos, neg = seq.to(device), pos.to(device), neg.to(device)\n",
    "\n",
    "        seq_repr = model(seq)\n",
    "        pos_emb = model.item_emb(pos)\n",
    "        neg_emb = model.item_emb(neg)\n",
    "\n",
    "        pos_score = (seq_repr * pos_emb).sum(dim=-1)\n",
    "        neg_score = (seq_repr * neg_emb).sum(dim=-1)\n",
    "\n",
    "        loss = -torch.mean(torch.log(torch.sigmoid(pos_score - neg_score)))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Keep model for later evaluation\n",
    "sasrec_model = model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30602644",
   "metadata": {},
   "source": [
    "### Training (BERT4Rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606e3529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss 23.1741\n",
      "Epoch 2: Loss 15.8258\n",
      "Epoch 3: Loss 12.7880\n",
      "Epoch 4: Loss 11.0311\n",
      "Epoch 5: Loss 9.8299\n",
      "Epoch 6: Loss 9.0530\n",
      "Epoch 7: Loss 8.5721\n",
      "Epoch 8: Loss 8.2285\n",
      "Epoch 9: Loss 8.0283\n",
      "Epoch 10: Loss 7.8777\n",
      "Epoch 11: Loss 7.7294\n",
      "Epoch 12: Loss 7.6659\n",
      "Epoch 13: Loss 7.5835\n",
      "Epoch 14: Loss 7.5338\n",
      "Epoch 15: Loss 7.4816\n",
      "Epoch 16: Loss 7.4594\n",
      "Epoch 17: Loss 7.4258\n",
      "Epoch 18: Loss 7.3971\n",
      "Epoch 19: Loss 7.3863\n",
      "Epoch 20: Loss 7.3700\n"
     ]
    }
   ],
   "source": [
    "# Prepare training set\n",
    "train_dataset = BERT4RecDataset(train_seqs, n_items)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize model, optimizer and loss function\n",
    "model = BERT4Rec(n_items, hidden_dim=64, max_len=MAX_SEQ_LEN).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "for epoch in range(20):  # small demo\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for masked_seq, labels in train_loader:\n",
    "        masked_seq, labels = masked_seq.to(device), labels.to(device)\n",
    "        outputs = model(masked_seq)  # [B, L, H]\n",
    "        logits = outputs @ model.item_emb.weight.T  # [B, L, n_items+2]\n",
    "\n",
    "        loss = criterion(logits.view(-1, n_items+2), labels.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}: Loss {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Keep model for later evaluation\n",
    "bert4rec_model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f9024",
   "metadata": {},
   "source": [
    "### Predict & Evaluate (Hit@K, NDCG@K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfdd946",
   "metadata": {},
   "source": [
    "#### Get Rank for a Single Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278e85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank(model, u, seed=42):\n",
    "    \"\"\"\n",
    "    Deterministic rank computation for a single user u.\n",
    "    Seeds Python/NumPy/torch RNGs and forces deterministic cuDNN behavior\n",
    "    so repeated calls return the same rank.\n",
    "    \"\"\"\n",
    "    # seed RNGs\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # make CUDA deterministic (may slow down)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    true_item = test_seqs[u][0]                                    # true next item for this user\n",
    "    seq = train_seqs[u]                                            # this user's previous movies\n",
    "    candidates = [x for x in range(1, n_items+1) if x not in seq]  # candidates = all movies - user's previous movies\n",
    "\n",
    "    # let true item be the first candidate for easier indexing later\n",
    "    candidates.remove(true_item)\n",
    "    candidates = [true_item] + candidates\n",
    "\n",
    "    scores = model.predict(seq, candidates, device).cpu().detach().numpy().flatten()  # score all candidates\n",
    "    \n",
    "    ranked = np.argsort(-scores)          # rank candidates by score (highest score first)\n",
    "    rank_of_true = list(ranked).index(0)  # 0 = index of true item in candidates\n",
    "    \n",
    "    return rank_of_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f3f6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "577"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rank(sasrec_model, 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0006f6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rank(bert4rec_model, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc7424",
   "metadata": {},
   "source": [
    "#### Evaluate Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc601ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, K=10):\n",
    "    model.eval()\n",
    "    hits, ndcgs = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for u in test_seqs:\n",
    "            # ignore users with no test items\n",
    "            if len(test_seqs[u]) == 0:\n",
    "                continue\n",
    "\n",
    "            # get rank of the true item\n",
    "            rank_of_true = get_rank(model, u)\n",
    "\n",
    "            # Metrics\n",
    "            if rank_of_true < K:\n",
    "                hits.append(1)\n",
    "                ndcgs.append(1 / np.log2(rank_of_true + 2))\n",
    "            else:\n",
    "                hits.append(0)\n",
    "                ndcgs.append(0)\n",
    "\n",
    "    hit_rate = np.mean(hits)\n",
    "    ndcg     = np.mean(ndcgs)\n",
    "    print(f\"Hit@{K}: {hit_rate:.4f}, NDCG@{K}: {ndcg:.4f}\\n\")\n",
    "\n",
    "    return hit_rate, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0544c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALiZaTo\\anaconda3\\envs\\torch-gpu\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:502: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\NestedTensorImpl.cpp:180.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@100: 0.0908, NDCG@100: 0.0206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hit_rate, ndcg = evaluate_model(sasrec_model, K=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b153c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit@100: 0.2328, NDCG@100: 0.0559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hit_rate, ndcg = evaluate_model(bert4rec_model, K=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-GPU-2.5.1",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
